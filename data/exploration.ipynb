{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [{'from': 'human', 'value': 'Provide a brief d...\n",
       "1         [{'from': 'human', 'value': '<image>\n",
       "Write a t...\n",
       "2         [{'from': 'human', 'value': 'Share a concise i...\n",
       "3         [{'from': 'human', 'value': 'Relay a brief, cl...\n",
       "4         [{'from': 'human', 'value': '<image>\n",
       "Render a ...\n",
       "                                ...                        \n",
       "595370    [{'from': 'human', 'value': 'Present a compact...\n",
       "595371    [{'from': 'human', 'value': '<image>\n",
       "Summarize...\n",
       "595372    [{'from': 'human', 'value': 'Describe the imag...\n",
       "595373    [{'from': 'human', 'value': '<image>\n",
       "Create a ...\n",
       "595374    [{'from': 'human', 'value': '<image>\n",
       "Provide a...\n",
       "Name: conversations, Length: 595375, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Convert JSON to DataFrame\n",
    "df = pd.read_json(\"chat.json\")\n",
    "\n",
    "df[\"conversations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Calculate the length of each text\n",
    "df['text_len'] = df['conversations'].apply(lambda x: len(x[0][\"value\"]) + len(x[1][\"value\"]))\n",
    "\n",
    "# Histogram\n",
    "fig_hist = px.histogram(df, x='text_len', nbins=40, title='Distribution of Text Lengths - Histogram')\n",
    "fig_hist.show()\n",
    "\n",
    "# Box Plot\n",
    "fig_box = px.box(df, y='text_len', title='Distribution of Text Lengths - Box Plot')\n",
    "fig_box.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from transformers import MBart50TokenizerFast\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\n",
    "    \"facebook/mbart-large-50-many-to-many-mmt\"\n",
    ")\n",
    "# Calculate the length of each text\n",
    "df['mbart-large-50-many-to-many-mmt_tokens_len'] = df['conversations'].apply(lambda x: len(tokenizer(x[0][\"value\"] + tokenizer.pad_token + x[1][\"value\"])[\"input_ids\"]))\n",
    "\n",
    "# Histogram\n",
    "fig_hist = px.histogram(df, x='mbart-large-50-many-to-many-mmt_tokens_len', nbins=40, title='Distribution of mbart-large-50-many-to-many-mmt tokens count - Histogram')\n",
    "fig_hist.show()\n",
    "\n",
    "# Box Plot\n",
    "fig_box = px.box(df, y='mbart-large-50-many-to-many-mmt_tokens_len', title='Distribution of mbart-large-50-many-to-many-mmt tokens count - Box Plot')\n",
    "fig_box.show()\n",
    "## MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from transformers import T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/madlad400-3b-mt\")\n",
    "# Calculate the length of each text\n",
    "df['madlad400_tokens_len'] = df['conversations'].apply(lambda x: len(tokenizer(x[0][\"value\"] + tokenizer.pad_token + x[1][\"value\"])[\"input_ids\"]))\n",
    "\n",
    "# Histogram\n",
    "fig_hist = px.histogram(df, x='madlad400_tokens_len', nbins=40, title='Distribution of madlad400-3b-mt tokens count - Histogram')\n",
    "fig_hist.show()\n",
    "\n",
    "# Box Plot\n",
    "fig_box = px.box(df, y='madlad400_tokens_len', title='Distribution of madlad400-3b-mt tokens count - Box Plot')\n",
    "fig_box.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['mbart-large-50-many-to-many-mmt_tokens_len'] <= 64) &  (df['mbart-large-50-many-to-many-mmt_tokens_len']<=64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"conversations\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dpowiedź: Podaj krótki opis danego obrazu<<<<<'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "model_name = 'jbochi/madlad400-3b-mt'\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "text = \"<2pl> Provide a brief description of the given image.\\n<image>.\"\n",
    "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "outputs = model.generate(input_ids=input_ids)\n",
    "\n",
    "tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "# Eu adoro pizza!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]%32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batches(df: pd.DataFrame, batch_size=32) -> list:\n",
    "    \"\"\"Batches list of data for training\"\"\"\n",
    "    batches_list = []\n",
    "    for i in range(df.shape[0]//batch_size):\n",
    "        ldx = i*batch_size\n",
    "        batches_list.append(df[\"conversations\"][ldx:ldx+batch_size])\n",
    "\n",
    "    batches_list.append(df[-(df.shape[0]%batch_size):]) \n",
    "    return batches_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast\n",
    "\n",
    "\n",
    "\n",
    "article_hi = \"Provide a brief description of the given image.\\n<image>.\"\n",
    "\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "\n",
    "# translate Hindi to French\n",
    "tokenizer.src_lang = \"en_EN\"\n",
    "encoded_hi = tokenizer(article_hi, return_tensors=\"pt\")\n",
    "generated_tokens = model.generate(\n",
    "    **encoded_hi,\n",
    "    forced_bos_token_id=tokenizer.lang_code_to_id[\"pl_PL\"]\n",
    ")\n",
    "tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.apply(lambda x: x[0][\"value\"]).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 10.00 GiB total capacity; 22.07 GiB already allocated; 0 bytes free; 23.60 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m T5ForConditionalGeneration, T5Tokenizer\n\u001b[0;32m      3\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjbochi/madlad400-3b-mt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mT5ForConditionalGeneration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda:0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m T5Tokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name, device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<2pl> Provide a brief description of the given image. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\tools\\mambaforge\\envs\\multimod\\lib\\site-packages\\transformers\\modeling_utils.py:3502\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3494\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[0;32m   3495\u001b[0m     (\n\u001b[0;32m   3496\u001b[0m         model,\n\u001b[0;32m   3497\u001b[0m         missing_keys,\n\u001b[0;32m   3498\u001b[0m         unexpected_keys,\n\u001b[0;32m   3499\u001b[0m         mismatched_keys,\n\u001b[0;32m   3500\u001b[0m         offload_index,\n\u001b[0;32m   3501\u001b[0m         error_msgs,\n\u001b[1;32m-> 3502\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[0;32m   3506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3509\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3510\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3513\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3514\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3518\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3520\u001b[0m \u001b[38;5;66;03m# make sure token embedding weights are still tied if needed\u001b[39;00m\n\u001b[0;32m   3521\u001b[0m model\u001b[38;5;241m.\u001b[39mtie_weights()\n",
      "File \u001b[1;32mc:\\tools\\mambaforge\\envs\\multimod\\lib\\site-packages\\transformers\\modeling_utils.py:3926\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[1;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_modules)\u001b[0m\n\u001b[0;32m   3924\u001b[0m                     hf_quantizer\u001b[38;5;241m.\u001b[39mcreate_quantized_param(model, param, key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m, state_dict)\n\u001b[0;32m   3925\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3926\u001b[0m         new_error_msgs, offload_index, state_dict_index \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_meta_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3927\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3928\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3929\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloaded_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3930\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3931\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3932\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3933\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3934\u001b[0m \u001b[43m            \u001b[49m\u001b[43moffload_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3935\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3936\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_dict_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate_dict_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3937\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3938\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3939\u001b[0m \u001b[43m            \u001b[49m\u001b[43mis_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3940\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3941\u001b[0m \u001b[43m            \u001b[49m\u001b[43munexpected_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munexpected_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3942\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3943\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[0;32m   3944\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\tools\\mambaforge\\envs\\multimod\\lib\\site-packages\\transformers\\modeling_utils.py:805\u001b[0m, in \u001b[0;36m_load_state_dict_into_meta_model\u001b[1;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, hf_quantizer, is_safetensors, keep_in_fp32_modules, unexpected_keys)\u001b[0m\n\u001b[0;32m    798\u001b[0m     state_dict_index \u001b[38;5;241m=\u001b[39m offload_weight(param, param_name, model, state_dict_folder, state_dict_index)\n\u001b[0;32m    799\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    800\u001b[0m     hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m hf_quantizer\u001b[38;5;241m.\u001b[39mrequires_parameters_quantization)\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m hf_quantizer\u001b[38;5;241m.\u001b[39mcheck_quantized_param(model, param, param_name, state_dict))\n\u001b[0;32m    803\u001b[0m ):\n\u001b[0;32m    804\u001b[0m     \u001b[38;5;66;03m# For backward compatibility with older versions of `accelerate` and for non-quantized params\u001b[39;00m\n\u001b[1;32m--> 805\u001b[0m     set_module_tensor_to_device(model, param_name, param_device, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mset_module_kwargs)\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    807\u001b[0m     hf_quantizer\u001b[38;5;241m.\u001b[39mcreate_quantized_param(model, param, param_name, param_device, state_dict, unexpected_keys)\n",
      "File \u001b[1;32mc:\\tools\\mambaforge\\envs\\multimod\\lib\\site-packages\\accelerate\\utils\\modeling.py:384\u001b[0m, in \u001b[0;36mset_module_tensor_to_device\u001b[1;34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map)\u001b[0m\n\u001b[0;32m    382\u001b[0m             module\u001b[38;5;241m.\u001b[39m_parameters[tensor_name] \u001b[38;5;241m=\u001b[39m param_cls(new_value, requires_grad\u001b[38;5;241m=\u001b[39mold_value\u001b[38;5;241m.\u001b[39mrequires_grad)\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m--> 384\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    386\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(value, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 10.00 GiB total capacity; 22.07 GiB already allocated; 0 bytes free; 23.60 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "model_name = 'jbochi/madlad400-3b-mt'\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name, device_map=\"cuda:0\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name, device_map=\"cuda:0\")\n",
    "\n",
    "text = \"<2pl> Provide a brief description of the given image. \\n\"\n",
    "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "outputs = model.generate(input_ids=input_ids)\n",
    "\n",
    "tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[   805,    113, 190947,  ...,      1,      1,      1],\n",
      "        [   805,    113,   1542,  ...,    807,      2,      1],\n",
      "        [   805,    113,  34666,  ...,      1,      1,      1],\n",
      "        ...,\n",
      "        [   805,    113, 156303,  ...,      2,      1,      1],\n",
      "        [   805,    113,   1544,  ...,    807,      2,      1],\n",
      "        [   805,    113,  34666,  ...,      1,      1,      1]],\n",
      "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Podaj krótki opis danego obrazu.',\n",
       " 'Napisz zwięzłe, ale pouczające podsumowanie obrazu.',\n",
       " 'Podziel się zwięzłą interpretacją dostarczonych obrazów.',\n",
       " 'Przekaż krótki, jasny opis pokazanego obrazu.',\n",
       " 'Wykonaj jasne i zwięzłe podsumowanie zdjęcia.',\n",
       " 'Stwórz zwartą narrację reprezentującą prezentowany obraz.',\n",
       " 'Wykonaj jasne i zwięzłe podsumowanie zdjęcia.',\n",
       " 'Podaj krótkie i jasne wyjaśnienie następującego obrazu.',\n",
       " 'Stwórz zwartą narrację reprezentującą prezentowany obraz.',\n",
       " 'Podsumuj wizualną zawartość obrazu.',\n",
       " 'Podaj krótki opis danego obrazu.',\n",
       " 'Podziel się zwięzłą interpretacją dostarczonych obrazów.',\n",
       " 'Stwórz zwartą narrację reprezentującą prezentowany obraz.',\n",
       " 'Podaj krótki opis danego obrazu.',\n",
       " 'Przekaż krótki, jasny opis pokazanego obrazu.',\n",
       " 'Stwórz zwartą narrację reprezentującą prezentowany obraz.',\n",
       " 'Podsumuj wizualną zawartość obrazu.',\n",
       " 'Podziel się zwięzłą interpretacją dostarczonych obrazów.',\n",
       " 'Podsumuj wizualną zawartość obrazu.',\n",
       " 'Opisz obraz zwięźle.',\n",
       " 'Podaj krótki opis danego obrazu.',\n",
       " 'Napisz zwięzłe, ale pouczające podsumowanie obrazu.',\n",
       " 'Podsumuj wizualną zawartość obrazu.',\n",
       " 'Napisz zwięzłe, ale pouczające podsumowanie obrazu.',\n",
       " 'Przekaż krótki, jasny opis pokazanego obrazu.',\n",
       " 'Zaoferuj zwięzłe wyjaśnienie przedstawionego obrazu.',\n",
       " 'Zaoferuj zwięzłe wyjaśnienie przedstawionego obrazu.',\n",
       " 'Zaoferuj zwięzłe wyjaśnienie przedstawionego obrazu.',\n",
       " 'Przedstaw zwięzły opis kluczowych cech zdjęcia.',\n",
       " 'Stwórz zwartą narrację reprezentującą prezentowany obraz.',\n",
       " 'Wykonaj jasne i zwięzłe podsumowanie zdjęcia.',\n",
       " 'Napisz zwięzłe, ale pouczające podsumowanie obrazu.',\n",
       " 'Podsumuj wizualną zawartość obrazu.',\n",
       " 'Wykonaj jasne i zwięzłe podsumowanie zdjęcia.',\n",
       " 'Opisz obraz zwięźle.',\n",
       " 'Opisz obraz zwięźle.',\n",
       " 'Zaoferuj zwięzłe wyjaśnienie przedstawionego obrazu.',\n",
       " 'Przekaż krótki, jasny opis pokazanego obrazu.',\n",
       " 'Podaj krótki opis danego obrazu.',\n",
       " 'Podziel się zwięzłą interpretacją dostarczonych obrazów.',\n",
       " 'Opisz obraz zwięźle.',\n",
       " 'Podaj krótkie i jasne wyjaśnienie następującego obrazu.',\n",
       " 'Zaoferuj zwięzłe wyjaśnienie przedstawionego obrazu.',\n",
       " 'Podaj krótki opis danego obrazu.',\n",
       " 'Stwórz zwartą narrację reprezentującą prezentowany obraz.',\n",
       " 'Napisz zwięzłe, ale pouczające podsumowanie obrazu.',\n",
       " 'Napisz zwięzłe, ale pouczające podsumowanie obrazu.',\n",
       " 'Przedstaw zwięzły opis kluczowych cech zdjęcia.',\n",
       " 'Napisz zwięzłe, ale pouczające podsumowanie obrazu.',\n",
       " 'Zaoferuj zwięzłe wyjaśnienie przedstawionego obrazu.',\n",
       " 'Podziel się zwięzłą interpretacją dostarczonych obrazów.',\n",
       " 'Podziel się zwięzłą interpretacją dostarczonych obrazów.',\n",
       " 'Stwórz zwartą narrację reprezentującą prezentowany obraz.',\n",
       " 'Przekaż krótki, jasny opis pokazanego obrazu.',\n",
       " 'Podaj krótkie i jasne wyjaśnienie następującego obrazu.',\n",
       " 'Napisz zwięzłe, ale pouczające podsumowanie obrazu.',\n",
       " 'Podziel się zwięzłą interpretacją dostarczonych obrazów.',\n",
       " 'Podsumuj wizualną zawartość obrazu.',\n",
       " 'Napisz zwięzłe, ale pouczające podsumowanie obrazu.',\n",
       " 'Podziel się zwięzłą interpretacją dostarczonych obrazów.',\n",
       " 'Przedstaw zwięzły opis kluczowych cech zdjęcia.',\n",
       " 'Opisz obraz zwięźle.',\n",
       " 'Opisz obraz zwięźle.',\n",
       " 'Podaj krótkie i jasne wyjaśnienie następującego obrazu.',\n",
       " 'Zaoferuj zwięzłe wyjaśnienie przedstawionego obrazu.',\n",
       " 'Stwórz zwartą narrację reprezentującą prezentowany obraz.',\n",
       " 'Przekaż krótki, jasny opis pokazanego obrazu.',\n",
       " 'Podaj krótki opis danego obrazu.',\n",
       " 'Wykonaj jasne i zwięzłe podsumowanie zdjęcia.',\n",
       " 'Przekaż krótki, jasny opis pokazanego obrazu.',\n",
       " 'Podziel się zwięzłą interpretacją dostarczonych obrazów.',\n",
       " 'Stwórz zwartą narrację reprezentującą prezentowany obraz.',\n",
       " 'Podaj krótki opis danego obrazu.',\n",
       " 'Wykonaj jasne i zwięzłe podsumowanie zdjęcia.',\n",
       " 'Podaj krótki opis danego obrazu.',\n",
       " 'Podaj krótkie i jasne wyjaśnienie następującego obrazu.',\n",
       " 'Wykonaj jasne i zwięzłe podsumowanie zdjęcia.',\n",
       " 'Przedstaw zwięzły opis kluczowych cech zdjęcia.',\n",
       " 'Podaj krótki opis danego obrazu.',\n",
       " 'Napisz zwięzłe, ale pouczające podsumowanie obrazu.',\n",
       " 'Przekaż krótki, jasny opis pokazanego obrazu.',\n",
       " 'Napisz zwięzłe, ale pouczające podsumowanie obrazu.',\n",
       " 'Podaj krótki opis danego obrazu.',\n",
       " 'Napisz zwięzłe, ale pouczające podsumowanie obrazu.',\n",
       " 'Opisz obraz zwięźle.',\n",
       " 'Podaj krótkie i jasne wyjaśnienie następującego obrazu.',\n",
       " 'Napisz zwięzłe, ale pouczające podsumowanie obrazu.',\n",
       " 'Podziel się zwięzłą interpretacją dostarczonych obrazów.',\n",
       " 'Napisz zwięzłe, ale pouczające podsumowanie obrazu.',\n",
       " 'Napisz zwięzłe, ale pouczające podsumowanie obrazu.',\n",
       " 'Przedstaw zwięzły opis kluczowych cech zdjęcia.',\n",
       " 'Zaoferuj zwięzłe wyjaśnienie przedstawionego obrazu.',\n",
       " 'Zaoferuj zwięzłe wyjaśnienie przedstawionego obrazu.',\n",
       " 'Zaoferuj zwięzłe wyjaśnienie przedstawionego obrazu.',\n",
       " 'Wykonaj jasne i zwięzłe podsumowanie zdjęcia.',\n",
       " 'Podaj krótkie i jasne wyjaśnienie następującego obrazu.',\n",
       " 'Przedstaw zwięzły opis kluczowych cech zdjęcia.',\n",
       " 'Wykonaj jasne i zwięzłe podsumowanie zdjęcia.',\n",
       " 'Zaoferuj zwięzłe wyjaśnienie przedstawionego obrazu.',\n",
       " 'Opisz obraz zwięźle.',\n",
       " 'Przekaż krótki, jasny opis pokazanego obrazu.',\n",
       " 'Przekaż krótki, jasny opis pokazanego obrazu.',\n",
       " 'Podaj krótkie i jasne wyjaśnienie następującego obrazu.',\n",
       " 'Przedstaw zwięzły opis kluczowych cech zdjęcia.',\n",
       " 'Podsumuj wizualną zawartość obrazu.',\n",
       " 'Podsumuj wizualną zawartość obrazu.',\n",
       " 'Podsumuj wizualną zawartość obrazu.',\n",
       " 'Podaj krótki opis danego obrazu.',\n",
       " 'Podaj krótkie i jasne wyjaśnienie następującego obrazu.',\n",
       " 'Podaj krótkie i jasne wyjaśnienie następującego obrazu.',\n",
       " 'Podaj krótkie i jasne wyjaśnienie następującego obrazu.',\n",
       " 'Przekaż krótki, jasny opis pokazanego obrazu.',\n",
       " 'Zaoferuj zwięzłe wyjaśnienie przedstawionego obrazu.',\n",
       " 'Przekaż krótki, jasny opis pokazanego obrazu.',\n",
       " 'Opisz obraz zwięźle.',\n",
       " 'Opisz obraz zwięźle.',\n",
       " 'Opisz obraz zwięźle.',\n",
       " 'Podziel się zwięzłą interpretacją dostarczonych obrazów.',\n",
       " 'Zaoferuj zwięzłe wyjaśnienie przedstawionego obrazu.',\n",
       " 'Podaj krótkie i jasne wyjaśnienie następującego obrazu.',\n",
       " 'Przedstaw zwięzły opis kluczowych cech zdjęcia.',\n",
       " 'Przedstaw zwięzły opis kluczowych cech zdjęcia.',\n",
       " 'Zaoferuj zwięzłe wyjaśnienie przedstawionego obrazu.',\n",
       " 'Przekaż krótki, jasny opis pokazanego obrazu.',\n",
       " 'Stwórz zwartą narrację reprezentującą prezentowany obraz.',\n",
       " 'Stwórz zwartą narrację reprezentującą prezentowany obraz.',\n",
       " 'Wykonaj jasne i zwięzłe podsumowanie zdjęcia.',\n",
       " 'Podziel się zwięzłą interpretacją dostarczonych obrazów.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches = process_batches(df=df, batch_size=32)\n",
    "trans_token = \"<2pl> \"\n",
    "for b in batches:\n",
    "    encoded_human = tokenizer(b.apply(lambda x: trans_token + x[0][\"value\"].replace(\"<image>\",'').replace(\"\\n\",\"\")).to_list(), return_tensors=\"pt\", max_length=64, padding=True)\n",
    "    encoded_ai = tokenizer(b.apply(lambda x: trans_token + x[1][\"value\"]).replace(\"<image>\",'').replace(\"\\n\",\"\").to_list(), return_tensors=\"pt\", max_length=64, padding=True)\n",
    "    break\n",
    "\n",
    "text =  encoded_human.to(\"cuda\")\n",
    "print(text)\n",
    "outputs = model.generate(**text)\n",
    "\n",
    "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Podaj krótki opis danego obrazu.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dpowiedz na pytanie: 1.'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   805,    113, 190947,    811, 127316, 153596,   1014,   1013,  74452,\n",
       "          28019,    807,      3,      2,      1,      1,      1,      1,      1,\n",
       "              1,      1],\n",
       "        [   805,    113,    805,      3,   2249,  17232,    811,  81080,   2590,\n",
       "         149583,    816, 160783,    873,   1014,   1013, 119364,    807,      2,\n",
       "              1,      1],\n",
       "        [   805,    113,  34666,    811,  82635,   3295,  38995,   4115,   1014,\n",
       "           1013,  28019, 169222,    807,      3,      2,      1,      1,      1,\n",
       "              1,      1],\n",
       "        [   805,    113,  53431,    873,    811, 127316,    806,  70792,  18640,\n",
       "           1014,   1013, 119364,  15637,    824,    807,      3,      2,      1,\n",
       "              1,      1],\n",
       "        [   805,    113,    805,      3,   5118,   7044,    811,  70792,   1055,\n",
       "          82635,   3295, 160783,    873,   1014,   1013,  20519,    807,      2,\n",
       "              1,      1],\n",
       "        [   805,    113, 156303,    811, 135385, 216364,    816,  57263,   1200,\n",
       "           1013,  28019,  34282,    909,    807,      3,      2,      1,      1,\n",
       "              1,      1],\n",
       "        [   805,    113,    805,      3,   5118,   7044,    811,  70792,   1055,\n",
       "          82635,   3295, 160783,    873,   1014,   1013,  20519,    807,      2,\n",
       "              1,      1],\n",
       "        [   805,    113,    805,      3, 198349,    811,  25007,   1055,  70792,\n",
       "         185468,    857,   3328,   1014,   1013,   3874, 213263,  28019,    807,\n",
       "              2,      1],\n",
       "        [   805,    113, 156303,    811, 135385, 216364,    816,  57263,   1200,\n",
       "           1013,  28019,  34282,    909,    807,      3,      2,      1,      1,\n",
       "              1,      1],\n",
       "        [   805,    113,    805,      3,   1172, 164205,  13219,   1013,  51620,\n",
       "          27065,   1014,   1013,  28019,    807,      2,      1,      1,      1,\n",
       "              1,      1],\n",
       "        [   805,    113,    805,      3,  31282,   2551,    811, 127316, 153596,\n",
       "           1014,   1013,  74452,  28019,    807,      2,      1,      1,      1,\n",
       "              1,      1],\n",
       "        [   805,    113,    805,      3, 177518,    811,  82635,   3295,  38995,\n",
       "           4115,   1014,   1013,  28019, 169222,    807,      2,      1,      1,\n",
       "              1,      1],\n",
       "        [   805,    113,    805,      3,   1208,    968,   3067,    811, 135385,\n",
       "         216364,    816,  57263,   1200,   1013,  28019,  34282,    909,    807,\n",
       "              2,      1],\n",
       "        [   805,    113,    805,      3,  31282,   2551,    811, 127316, 153596,\n",
       "           1014,   1013,  74452,  28019,    807,      2,      1,      1,      1,\n",
       "              1,      1],\n",
       "        [   805,    113,    805,      3,   5118,   4103,    811, 127316,    806,\n",
       "          70792,  18640,   1014,   1013, 119364,  15637,    824,    807,      2,\n",
       "              1,      1],\n",
       "        [   805,    113, 156303,    811, 135385, 216364,    816,  57263,   1200,\n",
       "           1013,  28019,  34282,    909,    807,      3,      2,      1,      1,\n",
       "              1,      1],\n",
       "        [   805,    113,  15162,   8184,   1463,   1013,  51620,  27065,   1014,\n",
       "           1013,  28019,    807,      3,      2,      1,      1,      1,      1,\n",
       "              1,      1],\n",
       "        [   805,    113,  34666,    811,  82635,   3295,  38995,   4115,   1014,\n",
       "           1013,  28019, 169222,    807,      3,      2,      1,      1,      1,\n",
       "              1,      1],\n",
       "        [   805,    113,    805,      3,   1172, 164205,  13219,   1013,  51620,\n",
       "          27065,   1014,   1013,  28019,    807,      2,      1,      1,      1,\n",
       "              1,      1],\n",
       "        [   805,    113,    805,      3,   4944, 137952,   1013,  28019,  82635,\n",
       "           3295,   1480,    807,      2,      1,      1,      1,      1,      1,\n",
       "              1,      1],\n",
       "        [   805,    113,    805,      3,  31282,   2551,    811, 127316, 153596,\n",
       "           1014,   1013,  74452,  28019,    807,      2,      1,      1,      1,\n",
       "              1,      1],\n",
       "        [   805,    113,   1542,  17232,    811,  81080,   2590, 149583,    816,\n",
       "         160783,    873,   1014,   1013, 119364,    807,      3,      2,      1,\n",
       "              1,      1],\n",
       "        [   805,    113,  15162,   8184,   1463,   1013,  51620,  27065,   1014,\n",
       "           1013,  28019,    807,      3,      2,      1,      1,      1,      1,\n",
       "              1,      1],\n",
       "        [   805,    113,    805,      3,   2249,  17232,    811,  81080,   2590,\n",
       "         149583,    816, 160783,    873,   1014,   1013, 119364,    807,      2,\n",
       "              1,      1],\n",
       "        [   805,    113,    805,      3,   5118,   4103,    811, 127316,    806,\n",
       "          70792,  18640,   1014,   1013, 119364,  15637,    824,    807,      2,\n",
       "              1,      1],\n",
       "        [   805,    113,    805,      3,   1191,  21520,    811, 195202,    889,\n",
       "          14238, 185468,    857,   3328,   1014,   1013, 119364,  34282,    909,\n",
       "            807,      2],\n",
       "        [   805,    113, 133841,    811, 195202,    889,  14238, 185468,    857,\n",
       "           3328,   1014,   1013, 119364,  34282,    909,    807,      3,      2,\n",
       "              1,      1],\n",
       "        [   805,    113, 133841,    811, 195202,    889,  14238, 185468,    857,\n",
       "           3328,   1014,   1013, 119364,  34282,    909,    807,      3,      2,\n",
       "              1,      1],\n",
       "        [   805,    113,  94913,    811, 135385, 153596,   1014,   1013,  20519,\n",
       "            814,    820,  12206,  64763,    807,      3,      2,      1,      1,\n",
       "              1,      1],\n",
       "        [   805,    113,    805,      3,   1208,    968,   3067,    811, 135385,\n",
       "         216364,    816,  57263,   1200,   1013,  28019,  34282,    909,    807,\n",
       "              2,      1],\n",
       "        [   805,    113,   1544,   7044,    811,  70792,   1055,  82635,   3295,\n",
       "         160783,    873,   1014,   1013,  20519,    807,      3,      2,      1,\n",
       "              1,      1],\n",
       "        [   805,    113,    805,      3,   2249,  17232,    811,  81080,   2590,\n",
       "         149583,    816, 160783,    873,   1014,   1013, 119364,    807,      2,\n",
       "              1,      1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "model_name = 'jbochi/madlad400-3b-mt'\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name, device_map=\"auto\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "text = \"<2pl> Create a compact narrative representing the image presented!\"\n",
    "input_ids = tokenizer(text, return_tensors=\"pt\").input_ids.to(model.device)\n",
    "outputs = model.generate(input_ids=input_ids)\n",
    "\n",
    "tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "# Eu adoro pizza!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "print(torch.cuda.device_count())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airoll",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
